{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoCo: 无监督视觉表征学习的动量对比\n",
    "\n",
    "MoCo是一种为比较学习构建动态词典的机制，可用于各种借口任务。在本文中，我们遵循一个简单的示例辨别任务：如果它们是同一图像的编码视图（例如，不同的裁剪），则查询匹配一个键。利用这个借口任务，MoCo展示了在Cifar10数据集中线性分类的通用协议下的竞争结果。\n",
    "\n",
    "## 模型简介\n",
    "\n",
    "MoCo网络从另外一个角度来理解对比学习，即从一个字典查询的角度来理解对比学习。MoCo中建立一个动态的字典，这个字典由两个部分组成：一个队列和一个移动平均的编码器。队列中的样本不需要做梯度反传，因此可以在队列中存储很多负样本，从而使这个字典可以变得很大。使用移动平均编码器的目的是使队列中的样本特征尽可能保持一致（即不同的样本通过尽量相似的编码器获得特征的编码表示）。在MoCo网络的构建过程中，使用Resnrt作为网络的骨干网络，除此之外，还需要利用动量更新机制去对网络进行动量更新，在模型结构中由一个momentum updata函数进行更新，在模型输出阶段，有infonce_loss函数来求模型损失值。MoCo网络结构示意图如下图所示。\n",
    "\n",
    "<p align=\"center\"><img src=\"image/moco.png\" width=\"300\"></p>\n",
    "\n",
    "## 对比损失机制\n",
    "\n",
    "比较了现今具有影响力的三种对比机制。为了关注对比损失机制的影响，我们以相同的借口任务实施了所有这些机制。并且还使用与对比损失函数相同的InfoNCE形式。因此，仅在三种机制上进行比较。结果在下图中。总体而言，这三种机制都受益于较大的K值。在内存机制下的中也观察到了类似的趋势，而在这里我们表明这种趋势更为普遍，并且可以在所有机制中看到。这些结果支持了我们建立大型字典去进行MOCO实验的动机。\n",
    "\n",
    "<p align=\"center\"><img src=\"image/construction.png\" width=\"400\"></p>\n",
    "\n",
    "## MoCo训练\n",
    "\n",
    "### 1 数据处理\n",
    "\n",
    "开始实验之前，请确保本地已经安装了Python环境并安装了MindSpore Vision套件。\n",
    "\n",
    "#### 1.1 数据准备\n",
    "\n",
    "本案例使用CIFAR-10数据集作为训练集与验证集来进行实验。CIFAR-10数据集包括10个类别的60000个32x32彩色图像，每个类别有6000个图像。有50000张训练图像和10000张测试图像。该数据集分为五个训练批次和一个测试批次，每个批次有10000张图像。测试批次包含从每个类中随机选择的正好1000个图像。训练批包含随机顺序的剩余图像，但是一些训练批可能包含来自一个类比另一个类的更多图像。其中，训练批次包含来自每个类的5000张图片。\n",
    "\n",
    "<p align=\"center\"><img src=\"image/cifar10.png\" width=\"200\"></p>\n",
    "\n",
    "#### 1.2 数据预处理\n",
    "\n",
    "在训练之前需要对数据集进行处理，本模型在训练过程中需要放入两张图片进行对比训练，所以在提取数据集的时候需要一下提取两张图片，在这个时候需要对数据进行数据集切片处理，而mindspore并没有现成的数据集切片API，那就自定义一个cifar10数据集类。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class CiFar10():\n",
    "    \"\"\" training set or test set.\"\"\"\n",
    "    train_list = [\n",
    "        'data_batch_1',\n",
    "        'data_batch_2',\n",
    "        'data_batch_3',\n",
    "        'data_batch_4',\n",
    "        'data_batch_5']\n",
    "    test_list = ['test_batch']\n",
    "\n",
    "    def __init__(self, root, train, transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            downloaded_list = self.train_list\n",
    "        else:\n",
    "            downloaded_list = self.test_list\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        for file_name in downloaded_list:\n",
    "            file_path = os.path.join(self.root, file_name)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                entry = pickle.load(f, encoding='latin1')\n",
    "                self.data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.targets.extend(entry['labels'])\n",
    "                else:\n",
    "                    self.targets.extend(entry['fine_labels'])\n",
    "\n",
    "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
    "        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image1, image2) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img1, img2 = self.data[index], self.data[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img1 = Image.fromarray(img1)\n",
    "        img2 = Image.fromarray(img2)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样就定义好了一个数据集自定义类，并且能够输出两张图片，接下来要用这来对具体的cifar10数据集进行数据增强。\n",
    "\n",
    "#### 1.3 数据增强\n",
    "\n",
    "数据增强分为训练图像增强和测试图像增强，因为只有训练时需要同时输入两张图片，测试时不需要两张图片，所以测试时应用MindSpore已有的Cifar10接口。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindvision.dataset import Cifar10\n",
    "import mindspore.dataset.vision.py_transforms as vp\n",
    "import mindspore.dataset.vision.c_transforms as vc\n",
    "import mindspore.dataset.transforms.c_transforms as c\n",
    "\n",
    "\n",
    "def create_dataset(data_path):\n",
    "    train_transform = c.Compose([\n",
    "        vc.RandomResizedCrop(32),\n",
    "        vc.RandomHorizontalFlip(0.5),\n",
    "        vp.ToTensor(),\n",
    "        vp.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "    test_transform = c.Compose([\n",
    "        vp.ToTensor(),\n",
    "        vp.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "    dataset1 = Cifar10(path=data_path, split=\"train\", batch_size=256, resize=32, shuffle=True,\n",
    "                       download=False, transform=train_transform)\n",
    "    dataset2 = Cifar10(path=data_path, split=\"train\", batch_size=256, resize=32, shuffle=False,\n",
    "                       download=False, transform=train_transform)\n",
    "    dataset3 = Cifar10(path=data_path, split=\"test\", batch_size=256, resize=32, shuffle=False,\n",
    "                       download=False, transform=test_transform)\n",
    "\n",
    "    train_data = dataset1.run()\n",
    "\n",
    "    memory_data = dataset2.run()\n",
    "\n",
    "    test_data = dataset3.run()\n",
    "\n",
    "    return train_data, memory_data, test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据增强接口就定义完成了，其中设置batch_size为256，对图像进行shuffle操作。接下来进行数据加载，看看效果。\n",
    "\n",
    "#### 1.4 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image1 shape: (256, 3, 32, 32)\n",
      "Image2 shape: (256, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "\n",
    "train_data, memory_data, test_data = create_dataset(\"src/Cifar10/cifar-10-batches-py\")\n",
    "\n",
    "data = next(train_data.create_dict_iterator())\n",
    "im1 = mindspore.Tensor(data[\"image\"].asnumpy())\n",
    "im2 = mindspore.Tensor(data[\"image\"].asnumpy())\n",
    "print(f'Image1 shape: {im1.shape}')\n",
    "print(f'Image2 shape: {im2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到训练数据输出shape为(256,3,32,32),图片大小为32x32，符合对输出的预期，数据集准备好了，接下来对模型进行构建，使用自定义Resnet模型作为backbone，构建MoCo网络。\n",
    "\n",
    "### 2 网络构建\n",
    "\n",
    "MoCo网络从另外一个角度来理解对比学习，即从一个字典查询的角度来理解对比学习。MoCo中建立一个动态的字典，这个字典由两个部分组成：一个队列和一个移动平均的编码器。队列中的样本不需要做梯度反传，因此可以在队列中存储很多负样本，从而使这个字典可以变得很大。使用移动平均编码器的目的是使队列中的样本特征尽可能保持一致（即不同的样本通过尽量相似的编码器获得特征的编码表示），其伪代码可见下图。\n",
    "\n",
    "<p align=\"center\"><img src=\"image/code.png\" width=\"600\"></p>\n",
    "\n",
    "#### 2.1 Resnet结构\n",
    "\n",
    "Resnet作为MoCo网络的backbone，具有非常特殊的结构，那就残差网络结构。Residual net(残差网络)：靠前若干层的某一层数据输出直接跳过多层引入到后面数据层的输入部分。残差神经单元：假定某段神经网络的输入是x,期望输出是H(x),如果我们直接将输入x传到输出作为初始结果，那么我们需要学习的目标就是F(x)=H(x)-x，这就是一个残差神经单元，相当于将学习目标改变了，不再是学习一个完整的输出H(x)，只是输出和输入的差别H(x)-x，即残差。Resnet18结构图如下所示。\n",
    "\n",
    "<p align=\"center\"><img src=\"image/resnet.jpg\" width=\"400\"></p>\n",
    "\n",
    "#### 2.2 Split_Batchnorm结构\n",
    "\n",
    "首先构建MindSpore框架下的Resnet网络结构，需要自定义Split_Batchnorm类，目的是用单GPU模型模拟多GPU模型结构，具体代码如下。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import mindspore.numpy as np\n",
    "import mindspore.ops as ops\n",
    "\n",
    "class SplitBatchNorm(nn.BatchNorm2d):\n",
    "    \"\"\"SplitBatchNorm:Simulate the behavior of BatchNorm's multiple gpus.\"\"\"\n",
    "    def __init__(self, num_features, num_splits=8, **kw):\n",
    "        super().__init__(num_features, **kw)\n",
    "        self.num_splits = num_splits\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        \"\"\" build SplitBatchNorm network.\"\"\"\n",
    "        n, c, h, w = inputs.shape\n",
    "\n",
    "        if self.training or not self.use_batch_statistics:\n",
    "            moving_mean_split = np.tile(self.moving_mean, self.num_splits)\n",
    "            moving_var_split = np.tile(self.moving_variance, self.num_splits)\n",
    "            outcome = ops.BatchNorm(is_training=True, epsilon=1e-5, momentum=0.9,\n",
    "                                    data_format=\"NCHW\")(inputs.view(-1, c * self.num_splits, h, w),\n",
    "                                                        np.tile(self.gamma, self.num_splits),\n",
    "                                                        np.tile(self.beta, self.num_splits), moving_mean_split,\n",
    "                                                        moving_var_split)[0]\n",
    "            outcome = outcome.view(n, c, h, w)\n",
    "            self.moving_mean.set_data(moving_mean_split.view(self.num_splits, c).mean(axis=0))\n",
    "            self.moving_variance.set_data(moving_var_split.view(self.num_splits, c).mean(axis=0))\n",
    "            return outcome\n",
    "        return ops.BatchNorm(is_training=False, epsilon=1e-5, momentum=0.9)(\n",
    "            inputs, self.moving_mean, self.moving_variance, self.gamma, self.beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 骨干网络\n",
    "\n",
    "构建BasicBlock类和Resnet类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore.ops import constexpr\n",
    "\n",
    "class BasicBlock(nn.Cell):\n",
    "    \"\"\"\n",
    "    BasicBlock of ResNet18\n",
    "\n",
    "    Args:\n",
    "        in_planes: Input channel\n",
    "        planes:  Output channel\n",
    "        kernel_size: Convolution kernel size\n",
    "        stride: Convolution step\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes, planes, kernel_size=3, stride=1):\n",
    "\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=kernel_size, stride=stride, padding=1, has_bias=False,\n",
    "                               pad_mode='pad', bias_init=\"zeros\", data_format=\"NCHW\")\n",
    "        self.bn1 = nn.BatchNorm2d(planes, eps=1e-5, momentum=0.99, affine=True, gamma_init='ones', beta_init='zeros',\n",
    "                                  moving_mean_init='zeros', moving_var_init='ones', use_batch_statistics=None, data_format='NCHW')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=kernel_size, stride=1, padding=1, has_bias=False,\n",
    "                               pad_mode='pad', bias_init=\"zeros\", data_format=\"NCHW\")\n",
    "        self.bn2 = nn.BatchNorm2d(planes, eps=1e-5, momentum=0.99, affine=True, gamma_init='ones', beta_init='zeros',\n",
    "                                  moving_mean_init='zeros', moving_var_init='ones', use_batch_statistics=None, data_format='NCHW')\n",
    "\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.downsample = nn.SequentialCell(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, has_bias=True, pad_mode='valid',\n",
    "                          bias_init=\"zeros\", data_format=\"NCHW\"), nn.BatchNorm2d(planes, eps=1e-5, momentum=0.99, affine=True, gamma_init='ones', beta_init='zeros',\n",
    "                                                                                 moving_mean_init='zeros', moving_var_init='ones', use_batch_statistics=None, data_format='NCHW'))\n",
    "        else:\n",
    "            self.downsample = nn.SequentialCell()\n",
    "\n",
    "    def construct(self, inx):\n",
    "        \"\"\"calculate basic module output.\"\"\"\n",
    "        x = self.relu(self.bn1(self.conv1(inx)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        out = x + self.downsample(inx)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "@constexpr\n",
    "def compute_kernel_size(inp_shape, output_size):\n",
    "    \"\"\"AdaptiveAvgPool2d script\"\"\"\n",
    "    kernel_width, kernel_height = inp_shape[2], inp_shape[3]\n",
    "    if isinstance(output_size, int):\n",
    "        kernel_width = math.ceil(kernel_width / output_size)\n",
    "        kernel_height = math.ceil(kernel_height / output_size)\n",
    "    elif isinstance(output_size, (list, tuple)):\n",
    "        kernel_width = math.ceil(kernel_width / output_size[0])\n",
    "        kernel_height = math.ceil(kernel_height / output_size[1])\n",
    "\n",
    "    return (kernel_width, kernel_height)\n",
    "\n",
    "\n",
    "class AdaptiveAvgPool2d(nn.Cell):\n",
    "    \"\"\"build AdaptiveAvgPool2d for Ascend.\"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def construct(self, x):\n",
    "        inp_shape = x.shape\n",
    "        kernel_size = compute_kernel_size(inp_shape, self.output_size)\n",
    "        return ops.AvgPool(kernel_size, kernel_size)(x)\n",
    "\n",
    "\n",
    "class ResNet18(nn.Cell):\n",
    "    \"\"\"backbone of MoCo\"\"\"\n",
    "    def __init__(self, basicblocks, blocknums, nb_classes):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3, stride=1, padding=1, has_bias=False,\n",
    "                               pad_mode='pad', bias_init=\"zeros\", data_format=\"NCHW\")\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes, eps=1e-5, momentum=0.99, affine=True, gamma_init='ones', beta_init='zeros',\n",
    "                                  moving_mean_init='zeros', moving_var_init='ones', use_batch_statistics=None, data_format='NCHW')\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.layer1 = self._make_layers(basicblocks, blocknums[0], 64, 1)\n",
    "        self.layer2 = self._make_layers(basicblocks, blocknums[1], 128, 2)\n",
    "        self.layer3 = self._make_layers(basicblocks, blocknums[2], 256, 2)\n",
    "        self.layer4 = self._make_layers(basicblocks, blocknums[3], 512, 2)\n",
    "        self.avgpool = AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Dense(in_channels=512, out_channels=nb_classes,\n",
    "                           weight_init='normal', bias_init='zeros', has_bias=True)\n",
    "\n",
    "    def _make_layers(self, basicblock, blocknum, plane, stride):\n",
    "        \"\"\"\n",
    "        make_layers for ResNet18\n",
    "\n",
    "        Args:\n",
    "            basicblock: Basic residual block class\n",
    "            blocknum: The number of basic residual blocks in the current layer is 2 for each layer of resnet18\n",
    "            plane: Number of output channels\n",
    "            stride: Convolution step\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        for i in range(blocknum):\n",
    "            if i == 0:\n",
    "                layer = basicblock(self.in_planes, plane, 3, stride=stride)\n",
    "            else:\n",
    "                layer = basicblock(plane, plane, 3, stride=1)\n",
    "            layers.append(layer)\n",
    "        self.in_planes = plane\n",
    "        return nn.SequentialCell(*layers)\n",
    "\n",
    "    def construct(self, inx):\n",
    "        \"\"\"calculate ResNet18 output.\"\"\"\n",
    "        x = self.relu(self.bn1(self.conv1(inx)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        out = self.fc(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 infoNCE 损失函数\n",
    "\n",
    "对于MoCo来说，也是需要构建损失函数来进行目标学习的，他学习的目标就是希望query与字典中那个与之相匹配的key越近似越好，与其他不匹配的越不相似越好。MoCo使用的是一种对比损失函数，叫InfoNCE损失函数。\n",
    "NCE(noise contrastive estimation)：当使用交叉熵的时候，如果类比太多(比如在这里，类别数相当于就是数据集图片数)，那么交叉熵是没法运行的。于是不如就是把多分类看成了数据样本和噪声样本两种类别，变成一系列的二分类问题，希望通过采样部分的负样本来近似使用全部负样本的效果。那么采样的负样本越多，自然就越接近全部样本的效果，但是同样也越难体现出交叉熵函数的作用。\n",
    "InfoNCE认为不能单纯的看成二分类问题，因为很多负样本本身还是很不相似的，所以还是需要看成多分类的：\n",
    "\n",
    "$$\\mathcal{L}_{q}=-\\log \\frac{\\exp \\left(q \\cdot k_{+} / \\tau\\right)}{\\sum_{i=0}^{K} \\exp \\left(q \\cdot k_{i} / \\tau\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infoNCE_loss(self, im_q, im_k):\n",
    "    \"\"\"infoNCE损失函数\"\"\"\n",
    "    # compute query features\n",
    "    q = self.encoder_q(im_q)  # queries: NxC\n",
    "    q = ops.L2Normalize(axis=1)(q)  # already normalized\n",
    "\n",
    "    # compute key features\n",
    "\n",
    "    # no gradient to keys\n",
    "    # shuffle for making use of BN\n",
    "    im_k_, idx_unshuffle = self.batch_shuffle_single_gpu(im_k)\n",
    "\n",
    "    k = self.encoder_k(im_k_)  # keys: NxC\n",
    "    k = ops.L2Normalize(axis=1)(k)  # already normalized\n",
    "\n",
    "    # undo shuffle\n",
    "    k = self.batch_unshuffle_single_gpu(k, idx_unshuffle)\n",
    "    k = ops.stop_gradient(k)\n",
    "\n",
    "    # compute logits\n",
    "    # Einstein sum is more intuitive\n",
    "    # positive logits: Nx1\n",
    "    einsum0 = ops.ReduceSum()(q * k, -1)\n",
    "    l_pos = ops.ExpandDims()(einsum0, -1)\n",
    "    # negative logits: NxK\n",
    "    l_neg = ops.MatMul()(q, self.queue)\n",
    "\n",
    "    # logits: Nx(1+K)\n",
    "    logits = ops.Concat(axis=1)((l_pos, l_neg))  # 按照维度连接两个张量\n",
    "    logits_n = ops.Cast()(logits, mindspore.float32)\n",
    "\n",
    "    # apply temperature\n",
    "    logits_x = logits_n / self.t\n",
    "\n",
    "    # labels: positive key indicators\n",
    "    labels_n = ops.Zeros()((logits.shape[0]), mindspore.int32)\n",
    "    labels = ops.Cast()(labels_n, mindspore.int32)\n",
    "\n",
    "    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')(logits_x, labels)\n",
    "    k = ops.stop_gradient(k)\n",
    "    loss = ops.stop_gradient(loss)\n",
    "\n",
    "    return loss, q, k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说明：infonce_loss是在moco网络内部定义的，这样提取出来，只作为展示，供参考\n",
    "\n",
    "#### 2.5 MoCo整体网络构建\n",
    "\n",
    "在完成了resent18网络和infonce loss的构建之后，需要将backbone嵌入到moco网络中，作为它的一部分，如伪代码所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "from mindspore import Tensor\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "\n",
    "class ModelMoCo(nn.Cell):\n",
    "    \"\"\"MoCo model based on ResNet18.\"\"\"\n",
    "    def __init__(self, i=4096, m=0.01, t=0.1, symmetric=False):\n",
    "        super(ModelMoCo, self).__init__()\n",
    "\n",
    "        self.i = i\n",
    "        self.m = m\n",
    "        self.t = t\n",
    "        self.symmetric = symmetric\n",
    "\n",
    "        # create the encoders\n",
    "        self.encoder_q = ResNet18(BasicBlock, [2, 2, 2, 2], 128)\n",
    "        self.encoder_k = ResNet18(BasicBlock, [2, 2, 2, 2], 128)\n",
    "\n",
    "        for param_q, param_k in zip(self.encoder_q.trainable_params(), self.encoder_k.trainable_params()):\n",
    "            param_k = param_q.clone()\n",
    "            param_k.requires_grad = False\n",
    "\n",
    "        self.queue = mindspore.Parameter(ops.Zeros()((128, 4096), mindspore.float32), name=\"queue\", requires_grad=False)\n",
    "        self.queue = ops.L2Normalize(axis=0)(self.queue)\n",
    "\n",
    "        self.queue_ptr = mindspore.Parameter(ops.Zeros()(1, mindspore.float32), name=\"queue_ptr\", requires_grad=False)\n",
    "\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"Momentum update of the key encoder.\"\"\"\n",
    "        for param_q, param_k in zip(self.encoder_q.trainable_params(),\n",
    "                                    self.encoder_k.trainable_params()):\n",
    "            param_k.set_data(param_k.data * (1 - self.m) + param_q.data * self.m)\n",
    "\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        \"\"\"encoding and decoding function.\"\"\"\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.T  # transpose\n",
    "        ptr = (ptr + batch_size) % self.i             # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    @staticmethod\n",
    "    def _batch_shuffle_single_gpu(x):\n",
    "        \"\"\"batch shuffle is used for multi gpu simulation.\"\"\"\n",
    "\n",
    "        # random shuffle index\n",
    "        n_x = Tensor([x.shape[0]], dtype=mindspore.int32)\n",
    "        randperm = ops.Randperm(max_length=x.shape[0], pad=-1)\n",
    "        idx_shuffle = randperm(n_x)\n",
    "        n_2 = ops.Cast()(idx_shuffle, mindspore.float32)\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle_2 = ops.Sort()(n_2)\n",
    "        idx_unshuffle = idx_unshuffle_2[1]\n",
    "\n",
    "        return x[idx_shuffle], idx_unshuffle\n",
    "\n",
    "    @staticmethod\n",
    "    def _batch_unshuffle_single_gpu(x, idx_unshuffle):\n",
    "        \"\"\"Undo batch shuffle is used for multi gpu simulation.\"\"\"\n",
    "\n",
    "        return x[idx_unshuffle]\n",
    "\n",
    "    def infonce_loss(self, im_q, im_k):\n",
    "        \"\"\"InfoNCE loss function.\"\"\"\n",
    "        # compute query features\n",
    "        q = self.encoder_q(im_q)  # queries: NxC\n",
    "        q = ops.L2Normalize(axis=1)(q)  # already normalized\n",
    "\n",
    "        # compute key features\n",
    "        im_k_, idx_unshuffle = ModelMoCo._batch_shuffle_single_gpu(im_k)\n",
    "\n",
    "        k = self.encoder_k(im_k_)  # keys: NxC\n",
    "        k = ops.L2Normalize(axis=1)(k)  # already normalized\n",
    "\n",
    "        # undo shuffle\n",
    "        k = ModelMoCo._batch_unshuffle_single_gpu(k, idx_unshuffle)\n",
    "        k = ops.stop_gradient(k)\n",
    "\n",
    "        einsum0 = ops.ReduceSum()(q * k, -1)\n",
    "        l_pos = ops.ExpandDims()(einsum0, -1)\n",
    "        # negative logits: NxK\n",
    "        l_neg = ops.MatMul()(q, self.queue)\n",
    "\n",
    "        # logits: Nx(1+K)\n",
    "        logits = ops.Concat(axis=1)((l_pos, l_neg))\n",
    "        logits_n = ops.Cast()(logits, mindspore.float32)\n",
    "\n",
    "        # apply temperature\n",
    "        logits_x = logits_n / self.t\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        labels_n = ops.Zeros()((logits.shape[0]), mindspore.int32)\n",
    "        labels = ops.Cast()(labels_n, mindspore.int32)\n",
    "\n",
    "        # Calculate the infonce loss\n",
    "        loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')(logits_x, labels)\n",
    "        k = ops.stop_gradient(k)\n",
    "        loss = ops.stop_gradient(loss)\n",
    "\n",
    "        return loss, k\n",
    "\n",
    "    def construct(self, im1, im2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            im_q: a batch of query images\n",
    "            im_k: a batch of key images\n",
    "        Output:\n",
    "            loss\n",
    "        \"\"\"\n",
    "        self._momentum_update_key_encoder()\n",
    "\n",
    "        # compute loss\n",
    "        if self.symmetric:\n",
    "            # asymmetric loss\n",
    "            loss_12, k2 = self.infonce_loss(im1, im2)\n",
    "            loss_21, k1 = self.infonce_loss(im2, im1)\n",
    "            loss = loss_12 + loss_21\n",
    "            k = ops.Concat(axis=0)(k1, k2)\n",
    "        else:\n",
    "            # asymmetric loss\n",
    "            loss, k = self.infonce_loss(im1, im2)\n",
    "        self._dequeue_and_enqueue(k)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此MoCo网络整体结构就搭建完成了，咱们可以打印一下其网络结构，查看网络内部结构组成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18<\n",
      "  (conv1): Conv2d<input_channels=3, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "  (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
      "  (relu): ReLU<>\n",
      "  (layer1): SequentialCell<\n",
      "    (0): BasicBlock<\n",
      "      (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer1.0.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer1.0.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer1.0.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer1.0.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
      "      (relu): ReLU<>\n",
      "      (conv2): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn2): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer1.0.bn2.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer1.0.bn2.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer1.0.bn2.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer1.0.bn2.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
      "      (downsample): SequentialCell<>\n",
      "      >\n",
      "    (1): BasicBlock<\n",
      "      (conv1): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn1): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer1.1.bn1.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer1.1.bn1.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer1.1.bn1.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer1.1.bn1.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
      "      (relu): ReLU<>\n",
      "      (conv2): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn2): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer1.1.bn2.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer1.1.bn2.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer1.1.bn2.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer1.1.bn2.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
      "      (downsample): SequentialCell<>\n",
      "      >\n",
      "    >\n",
      "  (layer2): SequentialCell<\n",
      "    (0): BasicBlock<\n",
      "      (conv1): Conv2d<input_channels=64, output_channels=128, kernel_size=(3, 3), stride=(2, 2), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn1): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer2.0.bn1.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer2.0.bn1.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer2.0.bn1.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer2.0.bn1.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
      "      (relu): ReLU<>\n",
      "      (conv2): Conv2d<input_channels=128, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn2): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer2.0.bn2.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer2.0.bn2.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer2.0.bn2.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer2.0.bn2.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
      "      (downsample): SequentialCell<\n",
      "        (0): Conv2d<input_channels=64, output_channels=128, kernel_size=(1, 1), stride=(2, 2), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        (1): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer2.0.downsample.1.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer2.0.downsample.1.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer2.0.downsample.1.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer2.0.downsample.1.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      >\n",
      "    (1): BasicBlock<\n",
      "      (conv1): Conv2d<input_channels=128, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn1): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer2.1.bn1.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer2.1.bn1.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer2.1.bn1.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer2.1.bn1.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
      "      (relu): ReLU<>\n",
      "      (conv2): Conv2d<input_channels=128, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn2): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer2.1.bn2.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer2.1.bn2.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer2.1.bn2.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer2.1.bn2.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
      "      (downsample): SequentialCell<>\n",
      "      >\n",
      "    >\n",
      "  (layer3): SequentialCell<\n",
      "    (0): BasicBlock<\n",
      "      (conv1): Conv2d<input_channels=128, output_channels=256, kernel_size=(3, 3), stride=(2, 2), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn1): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer3.0.bn1.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer3.0.bn1.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer3.0.bn1.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer3.0.bn1.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
      "      (relu): ReLU<>\n",
      "      (conv2): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn2): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer3.0.bn2.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer3.0.bn2.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer3.0.bn2.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer3.0.bn2.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
      "      (downsample): SequentialCell<\n",
      "        (0): Conv2d<input_channels=128, output_channels=256, kernel_size=(1, 1), stride=(2, 2), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        (1): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer3.0.downsample.1.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer3.0.downsample.1.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer3.0.downsample.1.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer3.0.downsample.1.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      >\n",
      "    (1): BasicBlock<\n",
      "      (conv1): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn1): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer3.1.bn1.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer3.1.bn1.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer3.1.bn1.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer3.1.bn1.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
      "      (relu): ReLU<>\n",
      "      (conv2): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn2): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer3.1.bn2.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer3.1.bn2.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer3.1.bn2.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer3.1.bn2.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
      "      (downsample): SequentialCell<>\n",
      "      >\n",
      "    >\n",
      "  (layer4): SequentialCell<\n",
      "    (0): BasicBlock<\n",
      "      (conv1): Conv2d<input_channels=256, output_channels=512, kernel_size=(3, 3), stride=(2, 2), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn1): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer4.0.bn1.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer4.0.bn1.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer4.0.bn1.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer4.0.bn1.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
      "      (relu): ReLU<>\n",
      "      (conv2): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn2): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer4.0.bn2.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer4.0.bn2.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer4.0.bn2.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer4.0.bn2.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
      "      (downsample): SequentialCell<\n",
      "        (0): Conv2d<input_channels=256, output_channels=512, kernel_size=(1, 1), stride=(2, 2), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "        (1): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer4.0.downsample.1.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer4.0.downsample.1.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer4.0.downsample.1.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer4.0.downsample.1.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
      "        >\n",
      "      >\n",
      "    (1): BasicBlock<\n",
      "      (conv1): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn1): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer4.1.bn1.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer4.1.bn1.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer4.1.bn1.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer4.1.bn1.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
      "      (relu): ReLU<>\n",
      "      (conv2): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=False, weight_init=normal, bias_init=zeros, format=NCHW>\n",
      "      (bn2): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.010000000000000009, gamma=Parameter (name=encoder_q.layer4.1.bn2.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=encoder_q.layer4.1.bn2.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=encoder_q.layer4.1.bn2.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=encoder_q.layer4.1.bn2.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
      "      (downsample): SequentialCell<>\n",
      "      >\n",
      "    >\n",
      "  (avgpool): AdaptiveAvgPool2d<>\n",
      "  (flatten): Flatten<>\n",
      "  (fc): Dense<input_channels=512, output_channels=128, has_bias=True>\n",
      "  >\n"
     ]
    }
   ],
   "source": [
    "models = ModelMoCo(i=4096, m=0.01, t=0.1, symmetric=False)\n",
    "print(models.encoder_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 模型训练\n",
    "\n",
    "在网络构建好之后，loss定义完成后，需要初始化优化器，然后加载数据集，设置好epoch以及学习率lr，就可以对网络进行训练了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1 / 30], step: [0 / 195], loss: 8.578479,lr: 0.058675967\n",
      "Epoch: [1 / 30], step: [25 / 195], loss: 7.855386,lr: 0.058675967\n",
      "Epoch: [1 / 30], step: [50 / 195], loss: 7.7259436,lr: 0.058675967\n",
      "Epoch: [1 / 30], step: [75 / 195], loss: 7.703345,lr: 0.058675967\n",
      "Epoch: [1 / 30], step: [100 / 195], loss: 7.7242727,lr: 0.058675967\n",
      "Epoch: [1 / 30], step: [125 / 195], loss: 7.7489104,lr: 0.058675967\n",
      "Epoch: [1 / 30], step: [150 / 195], loss: 7.7651553,lr: 0.058675967\n",
      "Epoch: [1 / 30], step: [175 / 195], loss: 7.767565,lr: 0.058675967\n",
      "time of one step: 0.3461952600723658 s/step, \n",
      "Epoch: [2 / 30], step: [0 / 195], loss: 7.6540165,lr: 0.05738115\n",
      "Epoch: [2 / 30], step: [25 / 195], loss: 7.599515,lr: 0.05738115\n",
      "Epoch: [2 / 30], step: [50 / 195], loss: 7.5501733,lr: 0.05738115\n",
      "Epoch: [2 / 30], step: [75 / 195], loss: 7.5048146,lr: 0.05738115\n",
      "Epoch: [2 / 30], step: [100 / 195], loss: 7.465658,lr: 0.05738115\n",
      "Epoch: [2 / 30], step: [125 / 195], loss: 7.4326143,lr: 0.05738115\n",
      "Epoch: [2 / 30], step: [150 / 195], loss: 7.403624,lr: 0.05738115\n",
      "Epoch: [2 / 30], step: [175 / 195], loss: 7.3781404,lr: 0.05738115\n",
      "time of one step: 0.3089974929124881 s/step, \n",
      "Epoch: [3 / 30], step: [0 / 195], loss: 7.195617,lr: 0.056114905\n",
      "Epoch: [3 / 30], step: [25 / 195], loss: 7.2001143,lr: 0.056114905\n",
      "Epoch: [3 / 30], step: [50 / 195], loss: 7.1997495,lr: 0.056114905\n",
      "Epoch: [3 / 30], step: [75 / 195], loss: 7.195924,lr: 0.056114905\n",
      "Epoch: [3 / 30], step: [100 / 195], loss: 7.1933546,lr: 0.056114905\n",
      "Epoch: [3 / 30], step: [125 / 195], loss: 7.1920075,lr: 0.056114905\n",
      "Epoch: [3 / 30], step: [150 / 195], loss: 7.1901727,lr: 0.056114905\n",
      "Epoch: [3 / 30], step: [175 / 195], loss: 7.1883907,lr: 0.056114905\n",
      "time of one step: 0.31373640940739556 s/step, \n",
      "Epoch: [4 / 30], step: [0 / 195], loss: 7.172989,lr: 0.054876607\n",
      "Epoch: [4 / 30], step: [25 / 195], loss: 7.1793094,lr: 0.054876607\n",
      "Epoch: [4 / 30], step: [50 / 195], loss: 7.1801906,lr: 0.054876607\n",
      "Epoch: [4 / 30], step: [75 / 195], loss: 7.181373,lr: 0.054876607\n",
      "Epoch: [4 / 30], step: [100 / 195], loss: 7.180782,lr: 0.054876607\n",
      "Epoch: [4 / 30], step: [125 / 195], loss: 7.181127,lr: 0.054876607\n",
      "Epoch: [4 / 30], step: [150 / 195], loss: 7.18128,lr: 0.054876607\n",
      "Epoch: [4 / 30], step: [175 / 195], loss: 7.181714,lr: 0.054876607\n",
      "time of one step: 0.3102473625769982 s/step, \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from mindspore import context\n",
    "\n",
    "def train(net, train_data, epoch, lr):\n",
    "    \"\"\"\n",
    "    MoCo train\n",
    "\n",
    "    Args:\n",
    "        net : MoCo model\n",
    "        train_data : train_data\n",
    "        epoch: epoch\n",
    "        args: train args\n",
    "        lr: learning rate\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    net.set_train()\n",
    "    total_loss, total_num, step = 0.0, 0, 0\n",
    "    steps = train_data.get_dataset_size()\n",
    "\n",
    "    for d in train_data.create_dict_iterator():\n",
    "        im1 = mindspore.Tensor(d[\"image\"].asnumpy())\n",
    "        #im2 = mindspore.Tensor(d[\"image2\"].asnumpy())\n",
    "        im2 = im1.copy()\n",
    "        loss = net(im1, im2)\n",
    "        total_num += 256\n",
    "        total_loss += loss * 256\n",
    "        if step % 25 == 0:\n",
    "            print(f\"Epoch: [{epoch} / {30}], \"\n",
    "                  f\"step: [{step} / {steps}], \"\n",
    "                  f\"loss: {total_loss / total_num},\"\n",
    "                  f\"lr: {lr}\")\n",
    "        step += 1\n",
    "    stop = time.time() - start\n",
    "    print(f\"time of one step: {stop/steps} s/step, \")\n",
    "    return total_loss / total_num\n",
    "\n",
    "train_data, memory_data, test_data = create_dataset(\"Cifar10/cifar-10-batches-py\")\n",
    "context.set_context(mode=context.PYNATIVE_MODE, device_target='Ascend')\n",
    "\n",
    "for epoch in range(1, 5):\n",
    "    exponential_decay_lr = nn.ExponentialDecayLR(0.06, 0.8, 10)\n",
    "    lr = exponential_decay_lr(epoch)\n",
    "    optimizer = nn.SGD(params=models.trainable_params(), learning_rate=lr, weight_decay=5e-4, momentum=0.9)\n",
    "    train_net = nn.TrainOneStepCell(models, optimizer)\n",
    "    start = time.time()\n",
    "    train_loss = train(train_net, train_data, epoch, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练完毕，那么接下来需要验证训练效果，从数据集提取验证数据集用于模型评估。\n",
    "\n",
    "### 4 模型评估\n",
    "\n",
    "需要自定义模型评估脚本，里面用到KNN近邻算法来预测数据。\n",
    "\n",
    "#### 4.1 KNN近邻算法\n",
    "\n",
    "简单说就是采用测量不同特征值之间的距离方法进行分类（k-Nearest Neighbor，KNN）,拥有精度高、对异常值不敏感、无数据输入假等特点。  \n",
    "1、当样本不平衡时，比如一个类的样本容量很大，其他类的样本容量很小，输入一个样本的时候，K个临近值中大多数都是大样本容量的那个类，这时可能就会导致分类错误。改进方法是对K临近点进行加权，也就是距离近的点的权值大，距离远的点权值小。  \n",
    "2、计算量较大，每个待分类的样本都要计算它到全部点的距离，根据距离排序才能求得K个临近点，改进方法是：先对已知样本点进行剪辑，事先去除对分类作用不大的样本。  \n",
    "适用数据范围：  \n",
    "1、标称型(离散型)：标称型目标变量的结果只在有限目标集中取值，如真与假(标称型目标变量主要用于分类)。  \n",
    "2、数值型：数值型目标变量则可以从无限的数值集合中取值，如0.100。\n",
    "\n",
    "<p align=\"center\"><img src=\"image/knn.png\" width=\"400\"></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore\n",
    "from mindspore import Tensor\n",
    "import mindspore.ops as ops\n",
    "import mindspore.dataset\n",
    "\n",
    "def knn_predict(feature, feature_bank, feature_labels, classes, knn_k, knn_t):\n",
    "    \"\"\"\n",
    "    knn_predict:compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
    "    knn monitor as in InstDisc https://arxiv.org/abs/1805.01978\n",
    "    implementation follows https://github.com/leftthomas/SimCLR\n",
    "    \"\"\"\n",
    "    sim_matrix = ops.MatMul()(feature, feature_bank)\n",
    "\n",
    "    topk = ops.TopK()\n",
    "    sim_weight, sim_indices = topk(sim_matrix, knn_k)\n",
    "\n",
    "    sim_labels = ops.GatherD()(ops.BroadcastTo((feature.shape[0], -1))(feature_labels), -1, sim_indices)\n",
    "    sim_weight = ops.Exp()(sim_weight / knn_t)\n",
    "\n",
    "    on_value, off_value = Tensor(1.0, mindspore.float32), Tensor(0.0, mindspore.float32)\n",
    "    one_hot_label = ops.OneHot(axis=-1)(sim_labels.view(-1), 10, on_value, off_value)\n",
    "\n",
    "    pred_scores = ops.ReduceSum()(one_hot_label.view(feature.shape[0], -1,\n",
    "                                                     classes) * ops.ExpandDims()(sim_weight, -1), 1)\n",
    "    sort = ops.Sort(axis=-1, descending=True)\n",
    "    pred_labels = sort(pred_scores)[1]\n",
    "\n",
    "    return pred_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 模型评估脚本\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, memory_data_loader, test_data_loader, epoch):\n",
    "    \"\"\"\n",
    "    test for MoCo\n",
    "\n",
    "    Args:\n",
    "        net : MoCo.encoder_q model\n",
    "        memory_data_loader : memory_data\n",
    "        test_data_loader: test_data\n",
    "        epoch: epoch\n",
    "        args: test args\n",
    "    \"\"\"\n",
    "    net.set_train(False)\n",
    "    classes = 10\n",
    "    total_top1, total_num, step, feature_bank = 0.0, 0, 0, []\n",
    "    x1 = np.random.normal(1, 1, (0))\n",
    "    steps = test_data_loader.get_dataset_size()\n",
    "\n",
    "    # generate feature bank\n",
    "    for data1 in memory_data_loader.create_dict_iterator():\n",
    "        feature = net(data1[\"image\"])\n",
    "        feature = ops.L2Normalize(axis=1)(feature)\n",
    "        feature_bank.append(feature)\n",
    "        x2 = data1[\"label\"].asnumpy()\n",
    "        x1 = np.concatenate([x1, x2], axis=0)\n",
    "\n",
    "    feature_bank1 = ops.Concat(axis=0)(feature_bank)\n",
    "    feature_bank2 = feature_bank1.T\n",
    "    feature_labels = mindspore.Tensor(x1, mindspore.int32)\n",
    "\n",
    "    # loop test data to predict the label by weighted knn search\n",
    "    for data2 in test_data_loader.create_dict_iterator():\n",
    "        feature = net(data2[\"image\"])\n",
    "        feature = ops.L2Normalize(axis=1)(feature)\n",
    "        pred_labels = knn_predict(feature, feature_bank2, feature_labels, classes, 200, 0.1)\n",
    "        cast = ops.Cast()\n",
    "        total_num += data2[\"image\"].shape[0]\n",
    "        number = cast((pred_labels[:, 0] == data2[\"label\"]), mindspore.float32)\n",
    "        total_top1 += number.sum()\n",
    "        if step % 5 == 0:\n",
    "\n",
    "            print(f\"Epoch: [{epoch} / {30}], \"\n",
    "                  f\"step: [{step} / {steps}], \"\n",
    "                  f\"Acc@1:{total_top1 / total_num * 100}%\")\n",
    "        step += 1\n",
    "\n",
    "    return total_top1 / total_num * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 模型评估整体\n",
    "\n",
    "在完成了KNN近邻函数和评估脚本的写后，然后可以直接调用，对模型进行评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1 / 30], step: [0 / 39], Acc@1:10.15625%\n",
      "Epoch: [1 / 30], step: [5 / 39], Acc@1:10.481771%\n",
      "Epoch: [1 / 30], step: [10 / 39], Acc@1:10.973012%\n",
      "Epoch: [1 / 30], step: [15 / 39], Acc@1:10.791016%\n",
      "Epoch: [1 / 30], step: [20 / 39], Acc@1:11.160714%\n",
      "Epoch: [1 / 30], step: [25 / 39], Acc@1:11.253004%\n",
      "Epoch: [1 / 30], step: [30 / 39], Acc@1:11.378529%\n",
      "Epoch: [1 / 30], step: [35 / 39], Acc@1:11.263021%\n",
      "Epoch: [2 / 30], step: [0 / 39], Acc@1:10.15625%\n",
      "Epoch: [2 / 30], step: [5 / 39], Acc@1:10.611979%\n",
      "Epoch: [2 / 30], step: [10 / 39], Acc@1:10.795455%\n",
      "Epoch: [2 / 30], step: [15 / 39], Acc@1:10.498047%\n",
      "Epoch: [2 / 30], step: [20 / 39], Acc@1:10.900298%\n",
      "Epoch: [2 / 30], step: [25 / 39], Acc@1:10.952524%\n",
      "Epoch: [2 / 30], step: [30 / 39], Acc@1:11.101311%\n",
      "Epoch: [2 / 30], step: [35 / 39], Acc@1:10.904947%\n",
      "Epoch: [3 / 30], step: [0 / 39], Acc@1:9.765625%\n",
      "Epoch: [3 / 30], step: [5 / 39], Acc@1:10.677084%\n",
      "Epoch: [3 / 30], step: [10 / 39], Acc@1:10.795455%\n",
      "Epoch: [3 / 30], step: [15 / 39], Acc@1:10.644531%\n",
      "Epoch: [3 / 30], step: [20 / 39], Acc@1:11.030505%\n",
      "Epoch: [3 / 30], step: [25 / 39], Acc@1:11.1328125%\n",
      "Epoch: [3 / 30], step: [30 / 39], Acc@1:11.290322%\n",
      "Epoch: [3 / 30], step: [35 / 39], Acc@1:11.154513%\n",
      "Epoch: [4 / 30], step: [0 / 39], Acc@1:10.9375%\n",
      "Epoch: [4 / 30], step: [5 / 39], Acc@1:11.263021%\n",
      "Epoch: [4 / 30], step: [10 / 39], Acc@1:11.505682%\n",
      "Epoch: [4 / 30], step: [15 / 39], Acc@1:11.1328125%\n",
      "Epoch: [4 / 30], step: [20 / 39], Acc@1:11.439733%\n",
      "Epoch: [4 / 30], step: [25 / 39], Acc@1:11.403246%\n",
      "Epoch: [4 / 30], step: [30 / 39], Acc@1:11.517138%\n",
      "Epoch: [4 / 30], step: [35 / 39], Acc@1:11.349826%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 5):\n",
    "    test_acc_1 = test(models.encoder_q, memory_data, test_data, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 模型推理（验证）\n",
    "\n",
    "模型训练评估好之后需要验证模型正确性，查看模型输出，验证可视化输出。\n",
    "<p align=\"center\">\n",
    "  <img src=\"image/visual_1.png\" width=\"600\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"image/visual_2.png\" width=\"600\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"image/visual_3.png\" width=\"600\">\n",
    "</p>\n",
    "\n",
    "### 6 总结\n",
    "\n",
    "本案例对Momentum Contrast for Unsupervised Visual Representation Learning这篇论文中提出的模型进行了详细的解释，向读者完整地展现了该算法的流程。如需查看详细代码，可参考course仓库。\n",
    "具体网址：https://gitee.com/mindspore/course/tree/master/application_example/MoCo\n",
    "\n",
    "### 引用\n",
    "\n",
    "[1] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, Ross Girshick:Momentum Contrast for Unsupervised Visual Representation Learning\n",
    "\n",
    "论文地址：https://arxiv.org/abs/1911.05722v3\n",
    "\n",
    "[2] Pytorch 开源代码：单GPU实现MoCo\n",
    "\n",
    "代码地址：https://github.com/leftthomas/MoCo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
